{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import librosa\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from sklearn.metrics import f1_score\n",
    "import wandb\n",
    "from audiomentations import AddBackgroundNoise\n",
    "from tensorflow.keras.layers import Lambda\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    SEED = 42\n",
    "    CLASSIFIER_LR = 3e-4\n",
    "    EPOCH = 200\n",
    "    BATCH_SIZE = 8\n",
    "\n",
    "    SR = 16000\n",
    "    DURATION = 20 # ms\n",
    "    FRAME_SIZE = 320\n",
    "\n",
    "    N_FFT = 64 # (SR*4ms/1000)\n",
    "    HOP_LENGTH = 32 # (SR*2ms/1000)\n",
    "    VOICE_DIR = './cv-corpus-19.0-2024-09-13/ko/clips/'\n",
    "    NOISE_DIR = './ESC-50-master/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_hann_window(window_length, dtype):\n",
    "    return 0.5 - 0.5 * tf.math.cos(2.0 *\n",
    "                                   np.pi *\n",
    "                                   tf.range(tf.cast(window_length, tf.float32)) /\n",
    "                                   tf.cast(window_length, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave2log_mel_spectrogram(wave):\n",
    "    signal_stft = tf.signal.stft(tf.cast(wave, tf.float32),\n",
    "                                 frame_length=400,\n",
    "                                 frame_step=160,\n",
    "                                 fft_length=1024,\n",
    "                                 window_fn=periodic_hann_window)\n",
    "    # print(signal_stft.shape) # (98, 513)\n",
    "    spectogram = tf.abs(signal_stft)\n",
    "\n",
    "    linear_to_mel = tf.signal.linear_to_mel_weight_matrix(40,\n",
    "                                signal_stft.shape[-1],\n",
    "                                16000,\n",
    "                                300.0,\n",
    "                                4000.0)\n",
    "    mel_spectrogram = tf.tensordot(spectogram, linear_to_mel, 1)\n",
    "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-12)\n",
    "    return log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def representative_data_gen():\n",
    "    valid_df = pd.read_csv('valid_dataset.csv')\n",
    "    for _, row in valid_df.iterrows():\n",
    "        path = row['path']\n",
    "        label = row['label']\n",
    "\n",
    "        audio_raw = tf.io.read_file(path)\n",
    "        wave, sr = tf.audio.decode_wav(audio_raw, desired_channels=1)\n",
    "        wave = tf.squeeze(wave, axis=-1)\n",
    "        # print(wave.shape) (16000, )\n",
    "        log_mel_spectrogram = wave2log_mel_spectrogram(wave)\n",
    "        log_mel_spectrogram = np.expand_dims(log_mel_spectrogram, axis=-1)\n",
    "        log_mel_spectrogram = np.expand_dims(log_mel_spectrogram, axis=0)\n",
    "\n",
    "        # print(log_mel_spectrogram.shape) \n",
    "\n",
    "        yield [log_mel_spectrogram.astype(np.float32)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1732266498.191898 2836236 tf_tfl_flatbuffer_helpers.cc:365] Ignored output_format.\n",
      "W0000 00:00:1732266498.191912 2836236 tf_tfl_flatbuffer_helpers.cc:368] Ignored drop_control_dependency.\n",
      "2024-11-22 18:08:18.192042: I tensorflow/cc/saved_model/reader.cc:83] Reading SavedModel from: ./vad_slimnet\n",
      "2024-11-22 18:08:18.192651: I tensorflow/cc/saved_model/reader.cc:52] Reading meta graph with tags { serve }\n",
      "2024-11-22 18:08:18.192661: I tensorflow/cc/saved_model/reader.cc:147] Reading SavedModel debug info (if present) from: ./vad_slimnet\n",
      "2024-11-22 18:08:18.197256: I tensorflow/cc/saved_model/loader.cc:236] Restoring SavedModel bundle.\n",
      "2024-11-22 18:08:18.216252: I tensorflow/cc/saved_model/loader.cc:220] Running initialization op on SavedModel bundle at path: ./vad_slimnet\n",
      "2024-11-22 18:08:18.224654: I tensorflow/cc/saved_model/loader.cc:466] SavedModel load for tags { serve }; Status: success: OK. Took 32615 microseconds.\n",
      "loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2_1@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): error: 'tf.TensorListReserve' op is neither a custom op nor a flex op\n",
      "loc(callsite(callsite(fused[\"TensorListStack:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2Stack/TensorListStack@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): error: 'tf.TensorListStack' op is neither a custom op nor a flex op\n",
      "loc(callsite(fused[\"TensorListSetItem:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while/TensorArrayV2Write/TensorListSetItem@functional_1_1_custom_attention_model_10_1_rnn_12_1_while_body_1940439\"] at callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]))): error: 'tf.TensorListSetItem' op is neither a custom op nor a flex op\n",
      "error: failed while converting: 'main': \n",
      "Some ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \n",
      "TF Select ops: TensorListReserve, TensorListSetItem, TensorListStack\n",
      "Details:\n",
      "\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x40xf32>>>) : {device = \"\"}\n",
      "\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<i32>, tensor<?x40xf32>) -> (tensor<!tf_type.variant<tensor<?x40xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n",
      "\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<2xi32>) -> (tensor<98x?x40xf32>) : {device = \"\", num_elements = 98 : i64}\n",
      "\n"
     ]
    },
    {
     "ename": "ConverterError",
     "evalue": "Could not translate MLIR to FlatBuffer.<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2_1@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2_1@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): see current operation: %13 = \"tf.TensorListReserve\"(%6, %3) {device = \"\"} : (tensor<2xi32>, tensor<i32>) -> tensor<!tf_type.variant<tensor<?x40xf32>>>\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2_1@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListStack:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2Stack/TensorListStack@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListStack' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListStack:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2Stack/TensorListStack@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): see current operation: %24 = \"tf.TensorListStack\"(%23#2, %6) <{num_elements = 98 : i64}> {device = \"\"} : (tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<2xi32>) -> tensor<98x?x40xf32>\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListStack:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2Stack/TensorListStack@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(fused[\"TensorListSetItem:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while/TensorArrayV2Write/TensorListSetItem@functional_1_1_custom_attention_model_10_1_rnn_12_1_while_body_1940439\"] at callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]))): 'tf.TensorListSetItem' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): called from\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(fused[\"TensorListSetItem:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while/TensorArrayV2Write/TensorListSetItem@functional_1_1_custom_attention_model_10_1_rnn_12_1_while_body_1940439\"] at callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]))): see current operation: %22 = \"tf.TensorListSetItem\"(%arg2, %arg1, %21) <{resize_if_index_out_of_bounds = false}> {device = \"\"} : (tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<i32>, tensor<?x40xf32>) -> tensor<!tf_type.variant<tensor<?x40xf32>>>\n<unknown>:0: note: loc(callsite(fused[\"TensorListSetItem:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while/TensorArrayV2Write/TensorListSetItem@functional_1_1_custom_attention_model_10_1_rnn_12_1_while_body_1940439\"] at callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]))): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: TensorListReserve, TensorListSetItem, TensorListStack\nDetails:\n\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x40xf32>>>) : {device = \"\"}\n\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<i32>, tensor<?x40xf32>) -> (tensor<!tf_type.variant<tensor<?x40xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<2xi32>) -> (tensor<98x?x40xf32>) : {device = \"\", num_elements = 98 : i64}\n\n<unknown>:0: note: see current operation: \n\"func.func\"() <{arg_attrs = [{tf_saved_model.index_path = [\"keras_tensor_12\"]}], function_type = (tensor<?x98x40x1xf32>) -> tensor<?x2xf32>, res_attrs = [{tf_saved_model.index_path = [\"output_0\"]}], sym_name = \"main\"}> ({\n^bb0(%arg0: tensor<?x98x40x1xf32>):\n  %0 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<2x40xf32>}> : () -> tensor<2x40xf32>\n  %1 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<1x1x40xf32>}> : () -> tensor<1x1x40xf32>\n  %2 = \"arith.constant\"() <{value = dense<[-0.00183030369, 0.00183030439]> : tensor<2xf32>}> : () -> tensor<2xf32>\n  %3 = \"arith.constant\"() <{value = dense<98> : tensor<i32>}> : () -> tensor<i32>\n  %4 = \"arith.constant\"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>\n  %5 = \"arith.constant\"() <{value = dense<[1, 0, 2]> : tensor<3xi32>}> : () -> tensor<3xi32>\n  %6 = \"arith.constant\"() <{value = dense<[-1, 40]> : tensor<2xi32>}> : () -> tensor<2xi32>\n  %7 = \"arith.constant\"() <{value = dense<0> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %8 = \"arith.constant\"() <{value = dense<40> : tensor<i32>}> : () -> tensor<i32>\n  %9 = \"arith.constant\"() <{value = dense<1> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %10 = \"arith.constant\"() <{value = dense<0> : tensor<i32>}> : () -> tensor<i32>\n  %11 = \"arith.constant\"() <{value = dense<1> : tensor<i32>}> : () -> tensor<i32>\n  %12 = \"arith.constant\"() <{value = dense<[0, 2, 1]> : tensor<3xi32>}> : () -> tensor<3xi32>\n  %13 = \"tf.TensorListReserve\"(%6, %3) {device = \"\"} : (tensor<2xi32>, tensor<i32>) -> tensor<!tf_type.variant<tensor<?x40xf32>>>\n  %14 = \"tfl.shape\"(%arg0) : (tensor<?x98x40x1xf32>) -> tensor<4xi32>\n  %15 = \"tfl.strided_slice\"(%14, %7, %9, %9) <{begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, offset = false, shrink_axis_mask = 1 : i32}> : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\n  %16 = \"tfl.pack\"(%15, %3, %8) <{axis = 0 : i32, values_count = 3 : i32}> : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<3xi32>\n  %17 = \"tfl.reshape\"(%arg0, %16) : (tensor<?x98x40x1xf32>, tensor<3xi32>) -> tensor<?x98x40xf32>\n  %18 = \"tfl.shape\"(%17) : (tensor<?x98x40xf32>) -> tensor<3xi32>\n  %19 = \"tfl.strided_slice\"(%18, %7, %9, %9) <{begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, offset = false, shrink_axis_mask = 1 : i32}> : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\n  %20 = \"tfl.pack\"(%19, %8) <{axis = 0 : i32, values_count = 2 : i32}> : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\n  %21 = \"tfl.fill\"(%20, %4) : (tensor<2xi32>, tensor<f32>) -> tensor<?x40xf32>\n  %22 = \"tfl.transpose\"(%17, %5) : (tensor<?x98x40xf32>, tensor<3xi32>) -> tensor<98x?x40xf32>\n  %23:6 = \"tfl.while\"(%10, %10, %13, %21, %21, %22) <{is_stateless = false}> ({\n  ^bb0(%arg6: tensor<i32>, %arg7: tensor<i32>, %arg8: tensor<!tf_type.variant<tensor<?x40xf32>>>, %arg9: tensor<?x40xf32>, %arg10: tensor<?x40xf32>):\n    %34 = \"func.call\"(%arg6, %arg7, %arg8, %arg9, %arg10, %22) <{callee = @\"functional_1_1/custom_attention_model_10_1/rnn_12_1/while_cond\"}> : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> tensor<i1>\n    \"tfl.yield\"(%34) : (tensor<i1>) -> ()\n  }, {\n  ^bb0(%arg1: tensor<i32>, %arg2: tensor<i32>, %arg3: tensor<!tf_type.variant<tensor<?x40xf32>>>, %arg4: tensor<?x40xf32>, %arg5: tensor<?x40xf32>):\n    %33:6 = \"func.call\"(%arg1, %arg2, %arg3, %arg4, %arg5, %22) <{callee = @\"functional_1_1/custom_attention_model_10_1/rnn_12_1/while_body\"}> : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>)\n    \"tfl.yield\"(%33#0, %33#1, %33#2, %33#3, %33#4, %33#5) : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> ()\n  }) : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>)\n  %24 = \"tf.TensorListStack\"(%23#2, %6) <{num_elements = 98 : i64}> {device = \"\"} : (tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<2xi32>) -> tensor<98x?x40xf32>\n  %25 = \"tfl.transpose\"(%24, %5) : (tensor<98x?x40xf32>, tensor<3xi32>) -> tensor<?x98x40xf32>\n  %26 = \"tfl.batch_matmul\"(%1, %25) <{adj_x = false, adj_y = true}> : (tensor<1x1x40xf32>, tensor<?x98x40xf32>) -> tensor<?x1x98xf32>\n  %27 = \"tfl.softmax\"(%26) <{beta = 1.000000e+00 : f32}> : (tensor<?x1x98xf32>) -> tensor<?x1x98xf32>\n  %28 = \"tfl.transpose\"(%27, %12) : (tensor<?x1x98xf32>, tensor<3xi32>) -> tensor<?x98x1xf32>\n  %29 = \"tfl.mul\"(%25, %28) <{fused_activation_function = \"NONE\"}> : (tensor<?x98x40xf32>, tensor<?x98x1xf32>) -> tensor<?x98x40xf32>\n  %30 = \"tfl.sum\"(%29, %11) <{keep_dims = false}> : (tensor<?x98x40xf32>, tensor<i32>) -> tensor<?x40xf32>\n  %31 = \"tfl.fully_connected\"(%30, %0, %2) <{fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"}> : (tensor<?x40xf32>, tensor<2x40xf32>, tensor<2xf32>) -> tensor<?x2xf32>\n  %32 = \"tfl.softmax\"(%31) <{beta = 1.000000e+00 : f32}> : (tensor<?x2xf32>) -> tensor<?x2xf32>\n  \"func.return\"(%32) : (tensor<?x2xf32>) -> ()\n}) {tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_keras_tensor_12:0\", outputs = \"StatefulPartitionedCall_1:0\"}, tf_saved_model.exported_names = [\"serving_default\"]} : () -> ()\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mConverterError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[48], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m converter\u001b[38;5;241m.\u001b[39mexperimental_enable_resource_variables \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# 모델 변환\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m tflite_model \u001b[38;5;241m=\u001b[39m \u001b[43mconverter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvad_slimnet.tflite\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mwb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m     19\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(tflite_model)\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1238\u001b[0m, in \u001b[0;36m_export_metrics.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(convert_func)\n\u001b[1;32m   1236\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1237\u001b[0m   \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m-> 1238\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_and_export_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert_func\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1190\u001b[0m, in \u001b[0;36mTFLiteConverterBase._convert_and_export_metrics\u001b[0;34m(self, convert_func, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1188\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save_conversion_params_metric()\n\u001b[1;32m   1189\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mprocess_time()\n\u001b[0;32m-> 1190\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_func\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1191\u001b[0m elapsed_time_ms \u001b[38;5;241m=\u001b[39m (time\u001b[38;5;241m.\u001b[39mprocess_time() \u001b[38;5;241m-\u001b[39m start_time) \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m   1192\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m result:\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1572\u001b[0m, in \u001b[0;36mTFLiteSavedModelConverterV2.convert\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1570\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m trackable_obj\n\u001b[1;32m   1571\u001b[0m gc\u001b[38;5;241m.\u001b[39mcollect()\n\u001b[0;32m-> 1572\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_from_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgraph_def\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/lite.py:1430\u001b[0m, in \u001b[0;36mTFLiteConverterBaseV2._convert_from_saved_model\u001b[0;34m(self, graph_def)\u001b[0m\n\u001b[1;32m   1427\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_base_converter_args())\n\u001b[1;32m   1428\u001b[0m converter_kwargs\u001b[38;5;241m.\u001b[39mupdate(quant_mode\u001b[38;5;241m.\u001b[39mconverter_flags())\n\u001b[0;32m-> 1430\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43m_convert_saved_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mconverter_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimize_tflite_model(\n\u001b[1;32m   1432\u001b[0m     result,\n\u001b[1;32m   1433\u001b[0m     quant_mode,\n\u001b[1;32m   1434\u001b[0m     _build_conversion_flags(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconverter_kwargs)\u001b[38;5;241m.\u001b[39mdebug_options,\n\u001b[1;32m   1435\u001b[0m     quant_io\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_new_quantizer,\n\u001b[1;32m   1436\u001b[0m )\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:212\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    211\u001b[0m     report_error_message(\u001b[38;5;28mstr\u001b[39m(converter_error))\n\u001b[0;32m--> 212\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m converter_error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Re-throws the exception.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m    214\u001b[0m   report_error_message(\u001b[38;5;28mstr\u001b[39m(error))\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/convert_phase.py:205\u001b[0m, in \u001b[0;36mconvert_phase.<locals>.actual_decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    204\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 205\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m   \u001b[38;5;28;01mexcept\u001b[39;00m ConverterError \u001b[38;5;28;01mas\u001b[39;00m converter_error:\n\u001b[1;32m    207\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m converter_error\u001b[38;5;241m.\u001b[39merrors:\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:1045\u001b[0m, in \u001b[0;36mconvert_saved_model\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m model_flags \u001b[38;5;241m=\u001b[39m build_model_flags(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1044\u001b[0m conversion_flags \u001b[38;5;241m=\u001b[39m build_conversion_flags(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m-> 1045\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1046\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1047\u001b[0m \u001b[43m    \u001b[49m\u001b[43mconversion_flags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1048\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1049\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdebug_info_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1050\u001b[0m \u001b[43m    \u001b[49m\u001b[43menable_mlir_converter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1051\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1052\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m/media/insung/새 볼륨/gamba/vad/myenv/lib/python3.10/site-packages/tensorflow/lite/python/convert.py:376\u001b[0m, in \u001b[0;36mconvert\u001b[0;34m(model_flags, conversion_flags, input_data_str, debug_info_str, enable_mlir_converter)\u001b[0m\n\u001b[1;32m    368\u001b[0m         conversion_flags\u001b[38;5;241m.\u001b[39mguarantee_all_funcs_one_use \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    369\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m convert(\n\u001b[1;32m    370\u001b[0m             model_flags,\n\u001b[1;32m    371\u001b[0m             conversion_flags,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m             enable_mlir_converter,\n\u001b[1;32m    375\u001b[0m         )\n\u001b[0;32m--> 376\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converter_error\n\u001b[1;32m    378\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _run_deprecated_conversion_binary(\n\u001b[1;32m    379\u001b[0m     model_flags\u001b[38;5;241m.\u001b[39mSerializeToString(),\n\u001b[1;32m    380\u001b[0m     conversion_flags\u001b[38;5;241m.\u001b[39mSerializeToString(),\n\u001b[1;32m    381\u001b[0m     input_data_str,\n\u001b[1;32m    382\u001b[0m     debug_info_str,\n\u001b[1;32m    383\u001b[0m )\n",
      "\u001b[0;31mConverterError\u001b[0m: Could not translate MLIR to FlatBuffer.<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2_1@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListReserve' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2_1@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): see current operation: %13 = \"tf.TensorListReserve\"(%6, %3) {device = \"\"} : (tensor<2xi32>, tensor<i32>) -> tensor<!tf_type.variant<tensor<?x40xf32>>>\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListReserve:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2_1@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(callsite(fused[\"TensorListStack:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2Stack/TensorListStack@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): 'tf.TensorListStack' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListStack:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2Stack/TensorListStack@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): see current operation: %24 = \"tf.TensorListStack\"(%23#2, %6) <{num_elements = 98 : i64}> {device = \"\"} : (tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<2xi32>) -> tensor<98x?x40xf32>\n<unknown>:0: note: loc(callsite(callsite(fused[\"TensorListStack:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/TensorArrayV2Stack/TensorListStack@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: loc(callsite(fused[\"TensorListSetItem:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while/TensorArrayV2Write/TensorListSetItem@functional_1_1_custom_attention_model_10_1_rnn_12_1_while_body_1940439\"] at callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]))): 'tf.TensorListSetItem' op is neither a custom op nor a flex op\n<unknown>:0: note: loc(callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"])): called from\n<unknown>:0: note: loc(fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]): called from\n<unknown>:0: note: loc(callsite(fused[\"TensorListSetItem:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while/TensorArrayV2Write/TensorListSetItem@functional_1_1_custom_attention_model_10_1_rnn_12_1_while_body_1940439\"] at callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]))): see current operation: %22 = \"tf.TensorListSetItem\"(%arg2, %arg1, %21) <{resize_if_index_out_of_bounds = false}> {device = \"\"} : (tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<i32>, tensor<?x40xf32>) -> tensor<!tf_type.variant<tensor<?x40xf32>>>\n<unknown>:0: note: loc(callsite(fused[\"TensorListSetItem:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while/TensorArrayV2Write/TensorListSetItem@functional_1_1_custom_attention_model_10_1_rnn_12_1_while_body_1940439\"] at callsite(callsite(fused[\"While:\", \"functional_1_1/custom_attention_model_10_1/rnn_12_1/while@__inference___call___1940569\"] at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall@__inference_signature_wrapper___call___1940604\"]) at fused[\"StatefulPartitionedCall:\", \"StatefulPartitionedCall_1\"]))): Error code: ERROR_NEEDS_FLEX_OPS\n<unknown>:0: error: failed while converting: 'main': \nSome ops are not supported by the native TFLite runtime, you can enable TF kernels fallback using TF Select. See instructions: https://www.tensorflow.org/lite/guide/ops_select \nTF Select ops: TensorListReserve, TensorListSetItem, TensorListStack\nDetails:\n\ttf.TensorListReserve(tensor<2xi32>, tensor<i32>) -> (tensor<!tf_type.variant<tensor<?x40xf32>>>) : {device = \"\"}\n\ttf.TensorListSetItem(tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<i32>, tensor<?x40xf32>) -> (tensor<!tf_type.variant<tensor<?x40xf32>>>) : {device = \"\", resize_if_index_out_of_bounds = false}\n\ttf.TensorListStack(tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<2xi32>) -> (tensor<98x?x40xf32>) : {device = \"\", num_elements = 98 : i64}\n\n<unknown>:0: note: see current operation: \n\"func.func\"() <{arg_attrs = [{tf_saved_model.index_path = [\"keras_tensor_12\"]}], function_type = (tensor<?x98x40x1xf32>) -> tensor<?x2xf32>, res_attrs = [{tf_saved_model.index_path = [\"output_0\"]}], sym_name = \"main\"}> ({\n^bb0(%arg0: tensor<?x98x40x1xf32>):\n  %0 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<2x40xf32>}> : () -> tensor<2x40xf32>\n  %1 = \"arith.constant\"() <{value = dense_resource<__elided__> : tensor<1x1x40xf32>}> : () -> tensor<1x1x40xf32>\n  %2 = \"arith.constant\"() <{value = dense<[-0.00183030369, 0.00183030439]> : tensor<2xf32>}> : () -> tensor<2xf32>\n  %3 = \"arith.constant\"() <{value = dense<98> : tensor<i32>}> : () -> tensor<i32>\n  %4 = \"arith.constant\"() <{value = dense<0.000000e+00> : tensor<f32>}> : () -> tensor<f32>\n  %5 = \"arith.constant\"() <{value = dense<[1, 0, 2]> : tensor<3xi32>}> : () -> tensor<3xi32>\n  %6 = \"arith.constant\"() <{value = dense<[-1, 40]> : tensor<2xi32>}> : () -> tensor<2xi32>\n  %7 = \"arith.constant\"() <{value = dense<0> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %8 = \"arith.constant\"() <{value = dense<40> : tensor<i32>}> : () -> tensor<i32>\n  %9 = \"arith.constant\"() <{value = dense<1> : tensor<1xi32>}> : () -> tensor<1xi32>\n  %10 = \"arith.constant\"() <{value = dense<0> : tensor<i32>}> : () -> tensor<i32>\n  %11 = \"arith.constant\"() <{value = dense<1> : tensor<i32>}> : () -> tensor<i32>\n  %12 = \"arith.constant\"() <{value = dense<[0, 2, 1]> : tensor<3xi32>}> : () -> tensor<3xi32>\n  %13 = \"tf.TensorListReserve\"(%6, %3) {device = \"\"} : (tensor<2xi32>, tensor<i32>) -> tensor<!tf_type.variant<tensor<?x40xf32>>>\n  %14 = \"tfl.shape\"(%arg0) : (tensor<?x98x40x1xf32>) -> tensor<4xi32>\n  %15 = \"tfl.strided_slice\"(%14, %7, %9, %9) <{begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, offset = false, shrink_axis_mask = 1 : i32}> : (tensor<4xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\n  %16 = \"tfl.pack\"(%15, %3, %8) <{axis = 0 : i32, values_count = 3 : i32}> : (tensor<i32>, tensor<i32>, tensor<i32>) -> tensor<3xi32>\n  %17 = \"tfl.reshape\"(%arg0, %16) : (tensor<?x98x40x1xf32>, tensor<3xi32>) -> tensor<?x98x40xf32>\n  %18 = \"tfl.shape\"(%17) : (tensor<?x98x40xf32>) -> tensor<3xi32>\n  %19 = \"tfl.strided_slice\"(%18, %7, %9, %9) <{begin_mask = 0 : i32, ellipsis_mask = 0 : i32, end_mask = 0 : i32, new_axis_mask = 0 : i32, offset = false, shrink_axis_mask = 1 : i32}> : (tensor<3xi32>, tensor<1xi32>, tensor<1xi32>, tensor<1xi32>) -> tensor<i32>\n  %20 = \"tfl.pack\"(%19, %8) <{axis = 0 : i32, values_count = 2 : i32}> : (tensor<i32>, tensor<i32>) -> tensor<2xi32>\n  %21 = \"tfl.fill\"(%20, %4) : (tensor<2xi32>, tensor<f32>) -> tensor<?x40xf32>\n  %22 = \"tfl.transpose\"(%17, %5) : (tensor<?x98x40xf32>, tensor<3xi32>) -> tensor<98x?x40xf32>\n  %23:6 = \"tfl.while\"(%10, %10, %13, %21, %21, %22) <{is_stateless = false}> ({\n  ^bb0(%arg6: tensor<i32>, %arg7: tensor<i32>, %arg8: tensor<!tf_type.variant<tensor<?x40xf32>>>, %arg9: tensor<?x40xf32>, %arg10: tensor<?x40xf32>):\n    %34 = \"func.call\"(%arg6, %arg7, %arg8, %arg9, %arg10, %22) <{callee = @\"functional_1_1/custom_attention_model_10_1/rnn_12_1/while_cond\"}> : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> tensor<i1>\n    \"tfl.yield\"(%34) : (tensor<i1>) -> ()\n  }, {\n  ^bb0(%arg1: tensor<i32>, %arg2: tensor<i32>, %arg3: tensor<!tf_type.variant<tensor<?x40xf32>>>, %arg4: tensor<?x40xf32>, %arg5: tensor<?x40xf32>):\n    %33:6 = \"func.call\"(%arg1, %arg2, %arg3, %arg4, %arg5, %22) <{callee = @\"functional_1_1/custom_attention_model_10_1/rnn_12_1/while_body\"}> : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>)\n    \"tfl.yield\"(%33#0, %33#1, %33#2, %33#3, %33#4, %33#5) : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> ()\n  }) : (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>) -> (tensor<i32>, tensor<i32>, tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<?x40xf32>, tensor<?x40xf32>, tensor<98x?x40xf32>)\n  %24 = \"tf.TensorListStack\"(%23#2, %6) <{num_elements = 98 : i64}> {device = \"\"} : (tensor<!tf_type.variant<tensor<?x40xf32>>>, tensor<2xi32>) -> tensor<98x?x40xf32>\n  %25 = \"tfl.transpose\"(%24, %5) : (tensor<98x?x40xf32>, tensor<3xi32>) -> tensor<?x98x40xf32>\n  %26 = \"tfl.batch_matmul\"(%1, %25) <{adj_x = false, adj_y = true}> : (tensor<1x1x40xf32>, tensor<?x98x40xf32>) -> tensor<?x1x98xf32>\n  %27 = \"tfl.softmax\"(%26) <{beta = 1.000000e+00 : f32}> : (tensor<?x1x98xf32>) -> tensor<?x1x98xf32>\n  %28 = \"tfl.transpose\"(%27, %12) : (tensor<?x1x98xf32>, tensor<3xi32>) -> tensor<?x98x1xf32>\n  %29 = \"tfl.mul\"(%25, %28) <{fused_activation_function = \"NONE\"}> : (tensor<?x98x40xf32>, tensor<?x98x1xf32>) -> tensor<?x98x40xf32>\n  %30 = \"tfl.sum\"(%29, %11) <{keep_dims = false}> : (tensor<?x98x40xf32>, tensor<i32>) -> tensor<?x40xf32>\n  %31 = \"tfl.fully_connected\"(%30, %0, %2) <{fused_activation_function = \"NONE\", keep_num_dims = false, weights_format = \"DEFAULT\"}> : (tensor<?x40xf32>, tensor<2x40xf32>, tensor<2xf32>) -> tensor<?x2xf32>\n  %32 = \"tfl.softmax\"(%31) <{beta = 1.000000e+00 : f32}> : (tensor<?x2xf32>) -> tensor<?x2xf32>\n  \"func.return\"(%32) : (tensor<?x2xf32>) -> ()\n}) {tf.entry_function = {control_outputs = \"\", inputs = \"serving_default_keras_tensor_12:0\", outputs = \"StatefulPartitionedCall_1:0\"}, tf_saved_model.exported_names = [\"serving_default\"]} : () -> ()\n"
     ]
    }
   ],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model('./vad_slimnet')\n",
    "converter.inference_input_type = tf.float32\n",
    "converter.inference_output_type = tf.float32\n",
    "\n",
    "\n",
    "converter.representative_dataset = representative_data_gen\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS, tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.EXPERIMENTAL_TFLITE_BUILTINS_ACTIVATIONS_INT16_WEIGHTS_INT8]\n",
    "converter._experimental_lower_tensor_list_ops = False\n",
    "\n",
    "converter.experimental_new_converter = True\n",
    "#converter.allow_custom_ops = False\n",
    "converter.experimental_enable_resource_variables = True\n",
    "\n",
    "# 모델 변환\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# TF Select ops: TensorListReserve, TensorListSetItem, TensorListStack 지원하지 않는다\n",
    "# https://www.tensorflow.org/lite/guide/op_select_allowlist?hl=ko&_gl=1*2zbz7k*_up*MQ..*_ga*MTU4NzE4MDgzMS4xNzMyMjY2NTQx*_ga_W0YLR4190T*MTczMjI2NjU0MS4xLjAuMTczMjI2NjU0MS4wLjAuMA..\n",
    "# raw ops로는 지원하나, tflite로는 지원하고 있지 않음\n",
    "\n",
    "# https://www.tensorflow.org/lite/guide/ops_compatibility?hl=ko&_gl=1*1747d60*_up*MQ..*_ga*MTU4NzE4MDgzMS4xNzMyMjY2NTQx*_ga_W0YLR4190T*MTczMjI2NjU0MS4xLjAuMTczMjI2NjY2Mi4wLjAuMA..\n",
    "# CUSTOM: 다음 TensorFlow Lite 연산도 제공되지만 사용자 정의 모델에 사용할 준비가 되지 않았습니다.\n",
    "with open('vad_slimnet.tflite', 'wb') as f:\n",
    "    f.write(tflite_model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
