{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_io as tfio\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from tensorflow.keras.layers import Input, Conv2D, Lambda\n",
    "from tensorflow.keras import Model, Layer\n",
    "\n",
    "from tensorflow.keras.utils import register_keras_serializable\n",
    "\n",
    "import numpy as np\n",
    "import random\n",
    "from audiomentations import AddBackgroundNoise\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from keras_tqdm import TQDMNotebookCallback\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'  # or any {'0', '1', '2'}\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CONFIG:\n",
    "    SEED = 42\n",
    "    CLASSIFIER_LR = 3e-4\n",
    "    EPOCH = 200\n",
    "    BATCH_SIZE = 8\n",
    "    VOICE_DIR = './cv-corpus-19.0-2024-09-13/ko/clips/'\n",
    "    NOISE_DIR = './ESC-50-master/audio/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def periodic_hann_window(window_length, dtype):\n",
    "    return 0.5 - 0.5 * tf.math.cos(2.0 *\n",
    "                                   np.pi *\n",
    "                                   tf.range(tf.cast(window_length, tf.float32)) /\n",
    "                                   tf.cast(window_length, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wave2log_mel_spectrogram(wave):\n",
    "    signal_stft = tf.signal.stft(tf.cast(wave, tf.float32),\n",
    "                                 frame_length=400,\n",
    "                                 frame_step=160,\n",
    "                                 fft_length=1024,\n",
    "                                 window_fn=periodic_hann_window)\n",
    "    # print(signal_stft.shape) # (98, 513)\n",
    "    spectogram = tf.abs(signal_stft)\n",
    "\n",
    "    linear_to_mel = tf.signal.linear_to_mel_weight_matrix(40,\n",
    "                                signal_stft.shape[-1],\n",
    "                                16000,\n",
    "                                300.0,\n",
    "                                4000.0)\n",
    "    mel_spectrogram = tf.tensordot(spectogram, linear_to_mel, 1)\n",
    "    log_mel_spectrogram = tf.math.log(mel_spectrogram + 1e-12)\n",
    "    return log_mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_generator(df):\n",
    "    for _, row in df.iterrows():\n",
    "        path = row['path']\n",
    "        label = row['label']\n",
    "\n",
    "        audio_raw = tf.io.read_file(path)\n",
    "        wave, sr = tf.audio.decode_wav(audio_raw, desired_channels=1)\n",
    "        wave = tf.squeeze(wave, axis=-1)\n",
    "        # print(wave.shape) (16000, )\n",
    "        log_mel_spectrogram = wave2log_mel_spectrogram(wave)\n",
    "        log_mel_spectrogram = np.expand_dims(log_mel_spectrogram, axis=-1)\n",
    "        # print(log_mel_spectrogram.shape) #(49, 80)\n",
    "\n",
    "        yield log_mel_spectrogram, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_df = pd.read_csv('valid_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('test_dataset.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_generator(lambda: data_generator(train_df), output_signature=(tf.TensorSpec(shape=(98, 40, 1), dtype=tf.float32), tf.TensorSpec(shape=(), dtype=tf.int32))).batch(CONFIG.BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = tf.data.Dataset.from_generator(lambda: data_generator(valid_df), output_signature=(tf.TensorSpec(shape=(98, 40, 1), dtype=tf.float32), tf.TensorSpec(shape=(), dtype=tf.int32))).batch(CONFIG.BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = tf.data.Dataset.from_generator(lambda: data_generator(test_df), output_signature=(tf.TensorSpec(shape=(98, 40, 1), dtype=tf.float32), tf.TensorSpec(shape=(), dtype=tf.int32))).batch(CONFIG.BATCH_SIZE).cache().prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">98</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">40</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_attention_model_10       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">13,082</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">CustomAttentionModel</span>)          │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m98\u001b[0m, \u001b[38;5;34m40\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ custom_attention_model_10       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │        \u001b[38;5;34m13,082\u001b[0m │\n",
       "│ (\u001b[38;5;33mCustomAttentionModel\u001b[0m)          │                        │               │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,082</span> (51.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m13,082\u001b[0m (51.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">13,082</span> (51.10 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m13,082\u001b[0m (51.10 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@tf.keras.utils.register_keras_serializable(package=\"Custom\")\n",
    "class CustomAttentionModel(Model):\n",
    "    def __init__(self, **kwargs):\n",
    "        super(CustomAttentionModel, self).__init__(**kwargs)\n",
    "        \n",
    "        # Define layers\n",
    "        self.lstm_cell = layers.LSTMCell(40)  # Single LSTM cell\n",
    "        self.rnn = layers.RNN(self.lstm_cell, return_sequences=True)\n",
    "        # self.lstm = layers.LSTM(40, return_sequences=True, input_shape=(98, 40))\n",
    "        self.dense = layers.Dense(2, activation='softmax')\n",
    "        self.query_vector = self.add_weight(\n",
    "            shape=(40,),\n",
    "            initializer=tf.keras.initializers.RandomNormal(),\n",
    "            trainable=True,\n",
    "            name=\"query_vector\",\n",
    "        )\n",
    "        self.reshape = layers.Reshape((98, 40))  # Reshape for RNN compatibility\n",
    "\n",
    "    def call(self, inputs):\n",
    "        # Forward pass\n",
    "        inputs = self.reshape(inputs)  # (batch_size, 98, 40)\n",
    "        lstm_output = self.rnn(inputs)  # (batch_size, time_steps, 40)\n",
    "\n",
    "        # Attention mechanism\n",
    "        query_vector = tf.expand_dims(self.query_vector, axis=0)  # Shape: (1, 40)\n",
    "        query_vector = tf.expand_dims(query_vector, axis=0)  # Shape: (1, 1, 40)\n",
    "        attention_scores = tf.matmul(lstm_output, query_vector, transpose_b=True)  # Shape: (batch_size, time_steps, 1)\n",
    "        attention_weights = tf.nn.softmax(attention_scores, axis=1)  # Shape: (batch_size, time_steps, 1)\n",
    "\n",
    "        # Context vector\n",
    "        context_vector = tf.reduce_sum(lstm_output * attention_weights, axis=1)  # Shape: (batch_size, 40)\n",
    "\n",
    "        # Classification\n",
    "        outputs = self.dense(context_vector)  # Shape: (batch_size, 2)\n",
    "        return outputs\n",
    "\n",
    "    def get_config(self):\n",
    "        config = super(CustomAttentionModel, self).get_config()\n",
    "        return config\n",
    "    \n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "    \n",
    "    \n",
    "# Instantiate and build the model\n",
    "inputs = tf.keras.Input(shape=(98, 40, 1))\n",
    "model = CustomAttentionModel()\n",
    "outputs = model(inputs)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "53/53 - 9s - 177ms/step - accuracy: 0.7052 - loss: 0.6163 - val_accuracy: 0.7212 - val_loss: 0.5844\n",
      "Epoch 2/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:53.014867: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:53.014916: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 1s - 16ms/step - accuracy: 1.0000 - loss: 0.3721 - val_accuracy: 1.0000 - val_loss: 0.3544\n",
      "Epoch 3/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:53.305270: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:53.305326: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 6ms/step - accuracy: 0.7406 - loss: 0.5416 - val_accuracy: 0.7115 - val_loss: 0.5379\n",
      "Epoch 4/200\n",
      "53/53 - 0s - 217us/step - accuracy: 1.0000 - loss: 0.3679 - val_accuracy: 1.0000 - val_loss: 0.2641\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:53.636232: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:53.642851: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:53.642881: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.7500 - loss: 0.5005 - val_accuracy: 0.7115 - val_loss: 0.5004\n",
      "Epoch 6/200\n",
      "53/53 - 0s - 200us/step - accuracy: 1.0000 - loss: 0.3650 - val_accuracy: 1.0000 - val_loss: 0.2199\n",
      "Epoch 7/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:53.927119: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:53.927142: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.7642 - loss: 0.4677 - val_accuracy: 0.7308 - val_loss: 0.4701\n",
      "Epoch 8/200\n",
      "53/53 - 0s - 200us/step - accuracy: 1.0000 - loss: 0.3559 - val_accuracy: 1.0000 - val_loss: 0.1939\n",
      "Epoch 9/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:54.215730: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:54.215754: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:54.222071: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:54.222087: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.7972 - loss: 0.4413 - val_accuracy: 0.7404 - val_loss: 0.4522\n",
      "Epoch 10/200\n",
      "53/53 - 0s - 193us/step - accuracy: 1.0000 - loss: 0.3372 - val_accuracy: 1.0000 - val_loss: 0.1727\n",
      "Epoch 11/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:54.503523: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:54.503544: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:54.509728: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:54.509744: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8137 - loss: 0.4212 - val_accuracy: 0.7500 - val_loss: 0.4409\n",
      "Epoch 12/200\n",
      "53/53 - 0s - 202us/step - accuracy: 1.0000 - loss: 0.3192 - val_accuracy: 1.0000 - val_loss: 0.1576\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:54.792541: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:54.792577: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:54.798880: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:54.798896: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8231 - loss: 0.4033 - val_accuracy: 0.7500 - val_loss: 0.4367\n",
      "Epoch 14/200\n",
      "53/53 - 0s - 195us/step - accuracy: 1.0000 - loss: 0.2979 - val_accuracy: 1.0000 - val_loss: 0.1412\n",
      "Epoch 15/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:55.080305: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:55.080329: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:55.086511: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:55.086533: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8278 - loss: 0.3885 - val_accuracy: 0.7500 - val_loss: 0.4368\n",
      "Epoch 16/200\n",
      "53/53 - 0s - 199us/step - accuracy: 1.0000 - loss: 0.2779 - val_accuracy: 1.0000 - val_loss: 0.1293\n",
      "Epoch 17/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:55.369839: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:55.369864: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:55.376035: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:55.376050: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8349 - loss: 0.3748 - val_accuracy: 0.7500 - val_loss: 0.4373\n",
      "Epoch 18/200\n",
      "53/53 - 0s - 201us/step - accuracy: 1.0000 - loss: 0.2671 - val_accuracy: 1.0000 - val_loss: 0.1190\n",
      "Epoch 19/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:55.657904: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:55.657928: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:55.664202: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:55.664218: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8373 - loss: 0.3624 - val_accuracy: 0.7500 - val_loss: 0.4380\n",
      "Epoch 20/200\n",
      "53/53 - 0s - 198us/step - accuracy: 1.0000 - loss: 0.2602 - val_accuracy: 1.0000 - val_loss: 0.1039\n",
      "Epoch 21/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:55.952474: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:55.952512: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8491 - loss: 0.3498 - val_accuracy: 0.7596 - val_loss: 0.4398\n",
      "Epoch 22/200\n",
      "53/53 - 0s - 200us/step - accuracy: 1.0000 - loss: 0.2501 - val_accuracy: 1.0000 - val_loss: 0.0849\n",
      "Epoch 23/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:56.240497: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:56.240521: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8491 - loss: 0.3373 - val_accuracy: 0.7596 - val_loss: 0.4432\n",
      "Epoch 24/200\n",
      "53/53 - 0s - 199us/step - accuracy: 1.0000 - loss: 0.2434 - val_accuracy: 1.0000 - val_loss: 0.0681\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:56.531259: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:56.531282: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8538 - loss: 0.3255 - val_accuracy: 0.7596 - val_loss: 0.4472\n",
      "Epoch 26/200\n",
      "53/53 - 0s - 199us/step - accuracy: 1.0000 - loss: 0.2407 - val_accuracy: 1.0000 - val_loss: 0.0569\n",
      "Epoch 27/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:56.820360: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:56.820385: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8561 - loss: 0.3124 - val_accuracy: 0.7500 - val_loss: 0.4558\n",
      "Epoch 28/200\n",
      "53/53 - 0s - 200us/step - accuracy: 1.0000 - loss: 0.2354 - val_accuracy: 1.0000 - val_loss: 0.0457\n",
      "Epoch 29/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:57.103093: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.103130: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:57.109425: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.109440: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8561 - loss: 0.3042 - val_accuracy: 0.7404 - val_loss: 0.4695\n",
      "Epoch 30/200\n",
      "53/53 - 0s - 200us/step - accuracy: 1.0000 - loss: 0.2336 - val_accuracy: 1.0000 - val_loss: 0.0370\n",
      "Epoch 31/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:57.393135: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.393156: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:57.399479: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.399496: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8585 - loss: 0.2955 - val_accuracy: 0.7596 - val_loss: 0.4781\n",
      "Epoch 32/200\n",
      "53/53 - 0s - 199us/step - accuracy: 1.0000 - loss: 0.2314 - val_accuracy: 1.0000 - val_loss: 0.0273\n",
      "Epoch 33/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:57.685232: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.685255: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:57.691531: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.691547: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8561 - loss: 0.2987 - val_accuracy: 0.7500 - val_loss: 0.4865\n",
      "Epoch 34/200\n",
      "53/53 - 0s - 189us/step - accuracy: 1.0000 - loss: 0.2324 - val_accuracy: 1.0000 - val_loss: 0.0398\n",
      "Epoch 35/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 17:59:57.976832: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.976856: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n",
      "2024-11-22 17:59:57.983233: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 17:59:57.983248: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53/53 - 0s - 5ms/step - accuracy: 0.8608 - loss: 0.2856 - val_accuracy: 0.7500 - val_loss: 0.4667\n",
      "Epoch 35: early stopping\n",
      "Restoring model weights from the end of the best epoch: 32.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model.compile(optimizer=Adam(learning_rate=CONFIG.CLASSIFIER_LR),\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, verbose=2, restore_best_weights=True)\n",
    "\n",
    "\n",
    "history = model.fit(train_dataset, verbose=2, epochs=CONFIG.EPOCH, validation_data=valid_dataset, callbacks=[early_stopping], steps_per_epoch=len(train_df)//CONFIG.BATCH_SIZE, validation_steps=len(valid_df)//CONFIG.BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m44/44\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 117ms/step - accuracy: 0.7644 - loss: 0.4906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-11-22 18:00:03.411261: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 1964356605870186667\n",
      "2024-11-22 18:00:03.411288: I tensorflow/core/framework/local_rendezvous.cc:424] Local rendezvous recv item cancelled. Key hash: 14900770143387590615\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "inputs = tf.random.normal([32, 98, 40, 1])  # Example input\n",
    "model(inputs)  # Build the model by passing inputs\n",
    "model.save('./vad_slimnet.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./vad_slimnet/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ./vad_slimnet/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved artifact at './vad_slimnet'. The following endpoints are available:\n",
      "\n",
      "* Endpoint 'serve'\n",
      "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 98, 40, 1), dtype=tf.float32, name='keras_tensor_12')\n",
      "Output Type:\n",
      "  TensorSpec(shape=(None, 2), dtype=tf.float32, name=None)\n",
      "Captures:\n",
      "  139327687697936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139329709788672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139327687699168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139329709415184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139327687688784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
      "  139327687703216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n"
     ]
    }
   ],
   "source": [
    "model.export('./vad_slimnet')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
